import cv2 as cv
import mediapipe as mp
import numpy as np
from utils3camerasys import get_projection_matrix, write_keypoints_to_disk
from scipy import linalg
from scipy.optimize import least_squares
import os

# Mediapipeå·¥å…·
mp_drawing = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands

# è®¾å®šè§†é¢‘å¸§åˆ†è¾¨ç‡ï¼ˆé«˜åº¦Ã—å®½åº¦ï¼‰
frame_shape = [1920, 1080]

# æ ‡å‡†éª¨éª¼é•¿åº¦ï¼ˆå•ä½ï¼šcmï¼‰ï¼Œè¯·æ ¹æ®å®é™…æ ‡å‡†æ¨¡å‹è®¾ç½®
std_lengths = {
    (3, 4): 2.34, (0, 5): 9.43, (17, 18): 2.86, (0, 17): 8.49,
    (13, 14): 3.81, (13, 17): 1.97, (18, 19): 1.83, (5, 6): 3.84,
    (5, 9): 2.33, (14, 15): 2.30, (0, 1): 4.11, (9, 10): 4.13,
    (1, 2): 3.75, (9, 13): 1.98, (10, 11): 2.53, (19, 20): 1.46,
    (6, 7): 2.20, (15, 16): 1.84, (2, 3): 2.87, (11, 12): 2.04,
    (7, 8): 1.82
}
# æ„é€ æ‰€æœ‰éª¨éª¼å¯¹ï¼ˆä½œä¸ºç´¢å¼•ä½¿ç”¨ï¼‰
bone_pairs = list(std_lengths.keys())

############################################
# ä¸‹é¢éƒ¨åˆ†å®ç° DLT+éçº¿æ€§é‡æŠ•å½±è¯¯å·®ä¼˜åŒ–è®¡ç®—3Dç‚¹
############################################

def DLT(P1, P2, P3, point1, point2, point3):
    """
    åˆ©ç”¨ä¸‰æ‘„åƒå¤´ DLT æ–¹æ³•æ±‚è§£åˆå§‹3Dç‚¹ï¼Œç„¶åé€šè¿‡éçº¿æ€§ä¼˜åŒ–ç»†åŒ–ç»“æœã€‚
    å‚æ•°:
      P1, P2, P3: ä¸‰ä¸ªæ‘„åƒå¤´çš„ 3Ã—4 æŠ•å½±çŸ©é˜µï¼ˆå·¦ã€å³ã€Kinectï¼‰
      point1, point2, point3: å¯¹åº”æ‘„åƒå¤´çš„ 2D å›¾åƒç‚¹ [x, y]
    è¿”å›:
      3D ç‚¹ [X, Y, Z]
    """
    A = np.zeros((6, 4))
    A[0, :] = point1[1] * P1[2, :] - P1[1, :]
    A[1, :] = P1[0, :] - point1[0] * P1[2, :]
    A[2, :] = point2[1] * P2[2, :] - P2[1, :]
    A[3, :] = P2[0, :] - point2[0] * P2[2, :]
    A[4, :] = point3[1] * P3[2, :] - P3[1, :]
    A[5, :] = P3[0, :] - point3[0] * P3[2, :]

    # åˆå§‹è§£ï¼ˆé½æ¬¡è§£å½’ä¸€åŒ–ï¼‰
    U, s, Vh = np.linalg.svd(A)
    X = Vh[-1, :]
    X = X / X[-1]
    initial_3d = X[:3]

    # é€šè¿‡éçº¿æ€§æœ€å°äºŒä¹˜å¯¹åˆå§‹è§£è¿›è¡Œç»†åŒ–
    refined_3d = nonlinear_refinement(P1, P2, P3, point1, point2, point3, initial_3d)
    return refined_3d

def nonlinear_refinement(P1, P2, P3, point1, point2, point3, initial_3d):
    """
    éçº¿æ€§ä¼˜åŒ–ç»†åŒ–å•ä¸ª3Dç‚¹ï¼Œä½¿å¾—æ‰€æœ‰è§†å›¾ä¸Šçš„é‡æŠ•å½±è¯¯å·®æœ€å°
    """
    def residual(X):
        res = []
        for P, pt in zip([P1, P2, P3], [point1, point2, point3]):
            X_h = np.hstack((X, 1))
            proj = P @ X_h
            proj = proj / proj[-1]
            res.extend(proj[:2] - pt)
        return res

    result = least_squares(residual, initial_3d)
    return result.x

############################################
# æ—¶åºå¹³æ»‘ï¼ˆç®€å•ç§»åŠ¨å¹³å‡ï¼‰
############################################

def temporal_smoothing(keypoints_seq, window_size=5):
    """
    å¯¹å•ä¸ªå…³èŠ‚åœ¨æ—¶åºæ•°æ®ä¸­çš„ 3D åæ ‡è¿›è¡Œç§»åŠ¨å¹³å‡å¹³æ»‘
    keypoints_seq: (N, 3) æ•°ç»„
    è¿”å›: å¹³æ»‘åçš„ (N, 3) åºåˆ—
    """
    smoothed = []
    for i in range(len(keypoints_seq)):
        start = max(0, i - window_size + 1)
        window = keypoints_seq[start:i+1]
        smoothed.append(np.mean(window, axis=0))
    return np.array(smoothed)

############################################
# ä¸»å‡½æ•°ï¼šå¤šæ‘„åƒå¤´ 2D æ£€æµ‹ä¸ 3D é‡å»º
############################################

def run_mp(input_stream_left, input_stream_right, input_stream_kinect, P_left, P_right, P_kinect):
    # æ‰“å¼€ä¸‰ä¸ªè§†é¢‘æµ
    cap_left = cv.VideoCapture(input_stream_left)
    cap_right = cv.VideoCapture(input_stream_right)
    cap_kinect = cv.VideoCapture(input_stream_kinect)
    caps = [cap_left, cap_right, cap_kinect]
    
    # æ£€æŸ¥è§†é¢‘æ˜¯å¦æ‰“å¼€
    if not cap_left.isOpened():
       print("Error: Cannot open left camera video")
       return
    if not cap_right.isOpened():
       print("Error: Cannot open right camera video")
       return
    if not cap_kinect.isOpened():
       print("Error: Cannot open kinect camera video")
       return

    print("ğŸ¥ Video files are loaded successfully")

    # è·å–å¸§ç‡ã€æ€»å¸§æ•°ï¼ˆå¯é€‰ï¼‰
    total_frames_left = int(cap_left.get(cv.CAP_PROP_FRAME_COUNT))
    total_frames_right = int(cap_right.get(cv.CAP_PROP_FRAME_COUNT))
    total_frames_kinect = int(cap_kinect.get(cv.CAP_PROP_FRAME_COUNT))
    fps_left = int(cap_left.get(cv.CAP_PROP_FPS))
    fps_right = int(cap_right.get(cv.CAP_PROP_FPS))
    fps_kinect = int(cap_kinect.get(cv.CAP_PROP_FPS))
    print(f"Left: {total_frames_left} frames, {fps_left} FPS; Right: {total_frames_right} frames, {fps_right} FPS; Kinect: {total_frames_kinect} frames, {fps_kinect} FPS")

    # åˆ›å»º Mediapipe æ‰‹éƒ¨æ£€æµ‹å¯¹è±¡ï¼ˆæ¯ä¸ªè§†å›¾å•ç‹¬åˆ›å»ºï¼‰
    hands_left = mp_hands.Hands(min_detection_confidence=0.6, max_num_hands=1, min_tracking_confidence=0.6)
    hands_right = mp_hands.Hands(min_detection_confidence=0.6, max_num_hands=1, min_tracking_confidence=0.6)
    hands_kinect = mp_hands.Hands(min_detection_confidence=0.6, max_num_hands=1, min_tracking_confidence=0.6)

    # ç”¨äºå­˜å‚¨å„è§†å›¾çš„2Då…³é”®ç‚¹å’Œæœ€ç»ˆè®¡ç®—çš„3Dæ•°æ®
    kpts_left, kpts_right, kpts_kinect, kpts_3d = [], [], [], []

    while cap_left.isOpened() and cap_right.isOpened() and cap_kinect.isOpened():
        ret_left, frame_left = cap_left.read()
        ret_right, frame_right = cap_right.read()
        ret_kinect, frame_kinect = cap_kinect.read()

        if not ret_left or not ret_right or not ret_kinect:
            print("ğŸš¨ Error: Video streams not returning frame data. Exiting...")
            break

        # è½¬æ¢ä¸º RGBï¼ˆMediapipeè¦æ±‚RGBè¾“å…¥ï¼‰
        frame_left_rgb = cv.cvtColor(frame_left, cv.COLOR_BGR2RGB)
        frame_right_rgb = cv.cvtColor(frame_right, cv.COLOR_BGR2RGB)
        frame_kinect_rgb = cv.cvtColor(frame_kinect, cv.COLOR_BGR2RGB)

        # Mediapipe å¤„ç†
        results_left = hands_left.process(frame_left_rgb)
        results_right = hands_right.process(frame_right_rgb)
        results_kinect = hands_kinect.process(frame_kinect_rgb)

        # æå–2Då…³é”®ç‚¹å‡½æ•°ï¼ˆè¿”å›21ä¸ªå…³é”®ç‚¹ï¼‰
        def extract_keypoints(results, frame):
            keypoints = []
            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    for p in range(21):
                        pxl_x = int(round(frame.shape[1] * hand_landmarks.landmark[p].x))
                        pxl_y = int(round(frame.shape[0] * hand_landmarks.landmark[p].y))
                        keypoints.append([pxl_x, pxl_y])
            else:
                keypoints = [[-1, -1]] * 21
            return keypoints

        frame_left_keypoints = extract_keypoints(results_left, frame_left)
        frame_right_keypoints = extract_keypoints(results_right, frame_right)
        frame_kinect_keypoints = extract_keypoints(results_kinect, frame_kinect)

        kpts_left.append(frame_left_keypoints)
        kpts_right.append(frame_right_keypoints)
        kpts_kinect.append(frame_kinect_keypoints)

        # å¯¹æ¯ä¸ªæ‰‹éƒ¨å…³é”®ç‚¹ï¼Œä½¿ç”¨ä¸‰æ‘„åƒå¤´æ•°æ®é€šè¿‡ DLT è®¡ç®— 3D ä½ç½®
        frame_p3ds = []
        for uv_left, uv_right, uv_kinect in zip(frame_left_keypoints, frame_right_keypoints, frame_kinect_keypoints):
            if uv_left[0] == -1 or uv_right[0] == -1 or uv_kinect[0] == -1:
                _p3d = [-1, -1, -1]  # è‹¥å­˜åœ¨æ— æ•ˆç‚¹åˆ™è¾“å‡ºæ— æ•ˆå€¼
            else:
                _p3d = DLT(P_left, P_right, P_kinect, uv_left, uv_right, uv_kinect)
            frame_p3ds.append(_p3d)
        # å°†å½“å‰å¸§çš„ 3D æ•°æ®ç»„ç»‡ä¸º (21, 3)
        frame_p3ds = np.array(frame_p3ds).reshape((21, 3))
        kpts_3d.append(frame_p3ds)

        # ç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹ä»¥ä¾¿è§‚å¯Ÿï¼ˆå¯é€‰ï¼‰
        def draw_landmarks(frame, results):
            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
        draw_landmarks(frame_left, results_left)
        draw_landmarks(frame_right, results_right)
        draw_landmarks(frame_kinect, results_kinect)

        # æ˜¾ç¤ºæ¯ä¸ªæ‘„åƒå¤´çš„ç”»é¢
        cv.imshow('Left Camera', frame_left)
        cv.imshow('Right Camera', frame_right)
        cv.imshow('Kinect Camera', frame_kinect)

        if cv.waitKey(1) & 0xFF == 27:
            break

    cv.destroyAllWindows()
    for cap in caps:
        cap.release()

    # å¯¹ 3D æ•°æ®åºåˆ—è¿›è¡Œæ—¶åºå¹³æ»‘å¤„ç†ï¼šå¯¹æ¯ä¸ªå…³èŠ‚åˆ†åˆ«å¹³æ»‘ï¼ˆå¯é€‰ï¼‰
    kpts_3d_smoothed = []
    for joint_idx in range(21):
        joint_seq = []
        for frame in kpts_3d:
            if frame[joint_idx][0] != -1:
                joint_seq.append(frame[joint_idx])
        if len(joint_seq) > 0:
            joint_seq = np.array(joint_seq)
            smoothed_joint_seq = temporal_smoothing(joint_seq, window_size=5)
            kpts_3d_smoothed.append(smoothed_joint_seq)
        else:
            kpts_3d_smoothed.append(np.array(joint_seq))
    # æ­¤å¤„ kpts_3d_smoothed æ˜¯æŒ‰å…³èŠ‚åˆ†å¼€å¹³æ»‘çš„æ—¶åºæ•°æ®ï¼Œå¯æ ¹æ®éœ€è¦é‡æ–°ç»„ç»‡

    # æ­¤å¤„è¿”å›åŸå§‹çš„ 3D æ•°æ®åºåˆ—ï¼ˆæœªæ—¶åºå¹³æ»‘ï¼‰ä¾›åç»­å¤„ç†
    return np.array(kpts_left), np.array(kpts_right), np.array(kpts_kinect), np.array(kpts_3d)

############################################
# åŸºäºæ ‡å‡†éª¨éª¼é•¿åº¦è¿›è¡Œå…¨å±€å°ºåº¦æ ¡æ­£
############################################

def calibrate_frame(X, std_lengths, bone_pairs):
    """
    å¯¹å•å¸§ Kinect 3D æ•°æ® Xï¼ˆå½¢çŠ¶ (21, 3)ï¼‰è¿›è¡Œå…¨å±€å°ºåº¦æ ¡æ­£ï¼Œ
    ä½¿å¾—å…³é”®éª¨éª¼å¯¹çš„é•¿åº¦ä¸æ ‡å‡†å€¼ç›¸ç¬¦ï¼ˆå•ä½ï¼šcmï¼‰ã€‚
    è¿”å›æ ¡æ­£åçš„ 3D æ•°æ® X_calib å’Œè®¡ç®—å¾—åˆ°çš„å°ºåº¦å› å­ sã€‚
    """
    scales = []
    for (i, j) in bone_pairs:
        if np.all(X[i] != -1) and np.all(X[j] != -1):
            measured = np.linalg.norm(X[i] - X[j])
            if measured > 0:
                scales.append(std_lengths[(i, j)] / measured)
    if len(scales) == 0:
        s = 1.0
    else:
        s = np.mean(scales)
    X_calib = X * s
    return X_calib, s

############################################
# ä¸»ç¨‹åºå…¥å£
############################################

if __name__ == '__main__':
    # è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆè¯·ç¡®ä¿è·¯å¾„æ­£ç¡®ï¼‰
    input_stream_left = r'captured_videos\motion_3\cam_1.avi'
    input_stream_right = r'captured_videos\motion_3\cam_2.avi'
    input_stream_kinect = r'captured_videos\motion_3\cam_kinect.avi'

    # è·å–å„æ‘„åƒå¤´çš„æŠ•å½±çŸ©é˜µï¼ˆå‡è®¾ get_projection_matrix å‡½æ•°å·²ç»å®ç°ï¼‰
    P_left = get_projection_matrix('kinect_left')
    P_right = get_projection_matrix('kinect_right')
    P_kinect = get_projection_matrix('kinect')

    print("âœ… All projection matrices are loaded")

    # è¿è¡Œ Mediapipe å¤šæ‘„åƒå¤´å¤„ç†ï¼Œå¾—åˆ°å„è§†å›¾çš„ 2D å…³é”®ç‚¹å’Œ 3D æ•°æ®ï¼ˆæœªç»è¿‡å…¨å±€å°ºåº¦æ ¡æ­£ï¼‰
    kpts_left, kpts_right, kpts_kinect, kpts_3d = run_mp(input_stream_left, input_stream_right, input_stream_kinect, P_left, P_right, P_kinect)
    print("finish!")

    # å¯¹æ¯ä¸€å¸§ Kinect å¾—åˆ°çš„ 3D æ•°æ®è¿›è¡Œå…¨å±€å°ºåº¦æ ¡æ­£
    calibrated_kpts_3d = []
    scale_factors = []
    for frame in kpts_3d:
        frame_calib, s = calibrate_frame(frame, std_lengths, bone_pairs)
        calibrated_kpts_3d.append(frame_calib)
        scale_factors.append(s)
    calibrated_kpts_3d = np.array(calibrated_kpts_3d)

    avg_scale = np.mean(scale_factors) if len(scale_factors) > 0 else 1.0
    print("âœ… Calibration done. Average scale factor: {:.3f}".format(avg_scale))

    # å°†æ ¡æ­£åçš„ 3D æ•°æ®å†™å…¥ç£ç›˜ï¼ˆä¾‹å¦‚ä¿å­˜åˆ°æ–‡ä»¶ kpts_3d_SVD.datï¼‰
    write_keypoints_to_disk('kpts_3d_SVD+handcalib.dat', calibrated_kpts_3d)
